# Streaming log analytics

In this integration <b>filebeat</b> will install in all servers where your application is deployed and <b>filebeat</b> will read and ship latest logs changes from these servers to <b>Kafka</b> topic as configured for this application.

<b>Logstash</b> will subscribe log lines from <b>kafka</b> topic and perform parsing on these lines make relevant changes, formatting, exclude and include fields then send this processed data to <b>Elasticsearch</b> Indexes as centralize location from different servers.

<b>Kibana</b> is linked with <b>Elasticsearch</b> indexes which will help to do analysis by search, charts and dashboards .
<br><br>

# Pipeline
![git_imame](https://user-images.githubusercontent.com/50271311/155036578-c1f2517f-cf4b-4eb0-a9fe-4d25d7031e70.png)
<br><br>

<img width="860" alt="image" src="https://user-images.githubusercontent.com/8248474/187525873-b734499a-425a-4900-9886-a4708192f2c2.png">



# Log generation

The logs are generated by 2 mechanisms:

1. Using metricbeats to generate the Oertaing system logs
2. Using the python log generator to generate the apache logs 

To generated logs using the python log generator to a file we can use the below command :

```bash
python3 log-generating-extensions/python-log-generator/main.py -n 100 -o LOG -p ../../elasticsearch/logs/ -s 10
```


# Getting started 
```bash
git clone https://github.com/snigdhasambitak/streaming-log-analytics.git
docker-compose up -d --build
```
<br>

Now we should see the below containers running 

<img width="1110" alt="image" src="https://user-images.githubusercontent.com/8248474/187526197-49814506-4ddc-4d6e-9fa5-c0357cdf2cd1.png">


# Kibana logs and visualisation
<img width="837" alt="image" src="https://user-images.githubusercontent.com/8248474/187525809-4caaec04-496f-4035-b386-b9da018747a5.png">


<img width="844" alt="image" src="https://user-images.githubusercontent.com/8248474/187525709-1a97ffc5-7f86-41b6-919d-3ddb00be6e74.png">

<br><br>

