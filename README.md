# Streaming log analytics

In this integration <b>filebeat</b> will install in all servers where your application is deployed and <b>filebeat</b> will read and ship latest logs changes from these servers to <b>Kafka</b> topic as configured for this application.

<b>Logstash</b> will subscribe log lines from <b>kafka</b> topic and perform parsing on these lines make relevant changes, formatting, exclude and include fields then send this processed data to <b>Elasticsearch</b> Indexes as centralize location from different servers.

<b>Kibana</b> is linked with <b>Elasticsearch</b> indexes which will help to do analysis by search, charts and dashboards .
<br><br>

# Pipeline
![git_imame](https://user-images.githubusercontent.com/50271311/155036578-c1f2517f-cf4b-4eb0-a9fe-4d25d7031e70.png)
<br><br>

![kafka_flow](<img width="865" alt="image" src="https://user-images.githubusercontent.com/8248474/187525222-a04c8af5-f90a-4961-939c-64bba2d5fbc1.png">)



# Log generation

The logs are generated by 2 mechanisms:

1. Using metricbeats to generate the Oertaing system logs
2. Using the python log generator to generate the apache logs 

To generated logs using the python log generator to a file we can use the below command :

```bash
python3 log-generating-extensions/python-log-generator/main.py -n 100 -o LOG -p ../../elasticsearch/logs/ -s 10
```


# Getting started 
```bash
git clone https://github.com/snigdhasambitak/streaming-log-analytics.git
docker-compose up -d --build
```
<br>

# Kibana logs and visualisation


![kibana_logs](<img width="841" alt="image" src="https://user-images.githubusercontent.com/8248474/187525107-824d9292-17b7-4548-b326-9cb0c1f53476.png">
)
![kibana](<img width="832" alt="image" src="https://user-images.githubusercontent.com/8248474/187524878-833f86ee-f6a6-4e4d-9eb9-ce3d906596d4.png">
)
<br><br>

